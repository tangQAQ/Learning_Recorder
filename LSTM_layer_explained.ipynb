{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq4mQMiMOZMwcI+KgJKYyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tangQAQ/Learning_Recorder/blob/main/LSTM_layer_explained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg23f9dOVoCz",
        "outputId": "d2a29156-63e6-47ec-8a62-721e6f77a4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device = tf.test.gpu_device_name()\n",
        "\n",
        "if device != '/device:GPU:0':\n",
        "  print('GPU not find')\n",
        "else: \n",
        "  print(f'Found GPU at{device}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras.backend as k\n",
        "from tensorflow.keras import models, Input\n",
        "from numpy import array_equal\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Flatten, TimeDistributed, RepeatVector "
      ],
      "metadata": {
        "id": "qRoIo_vpWDy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequence(length, n_unique):\n",
        "  return [randint(0, n_unique-1) for _ in range(length)]\n",
        "\n",
        "def one_hot_encode(sequence, n_unique):\n",
        "  encoding = list()\n",
        "  for value in sequence:\n",
        "    vector = [0 for _ in range(n_unique)]\n",
        "    vector[value] = 1\n",
        "    encoding.append(vector)\n",
        "  return array(encoding)\n",
        "\n",
        "def one_hot_decode(encoded_seq):\n",
        "  return [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "def get_reversed_pairs(time_steps, vocabulary_size, verbose=False):\n",
        "  sequence_in = generate_sequence(time_steps, vocabulary_size)\n",
        "  sequence_out = sequence_in[::-1]\n",
        "\n",
        "  X = one_hot_encode(sequence_in, vocabulary_size)\n",
        "  y = one_hot_encode(sequence_out, vocabulary_size)\n",
        "\n",
        "  X = X.reshape((1, X.shape[0], X.shape[1]))\n",
        "  y = y.reshape((1, y.shape[0], y.shape[1]))\n",
        "\n",
        "  if(verbose):\n",
        "    print('Generated sequences as follows')\n",
        "    print('\\nOne Sample Input Sequence in raw format:')\n",
        "    print('X[0]=%s' % (one_hot_decode(X[0])))\n",
        "    print('\\nIn one_hot_encoded format:')\n",
        "    print('X[0]=%s' % (X[0]))\n",
        "    print('\\nShape of an input to LSTm (X[0].shape):', X.shape)\n",
        "  return X,y\n",
        "\n",
        "def create_dataset(train_size, test_size, time_steps, vocabulary_size):\n",
        "  pairs = [get_reversed_pairs(time_steps, vocabulary_size) for _ in range(train_size)]\n",
        "  pairs = np.array(pairs).squeeze()\n",
        "  X_train = pairs[:, 0]\n",
        "  y_train = pairs[:, 1]\n",
        "  pairs = [get_reversed_pairs(time_steps, vocabulary_size) for _ in range(test_size)]\n",
        "  pairs = np.array(pairs).squeeze()\n",
        "  X_test = pairs[:, 0]\n",
        "  y_test = pairs[:, 1]\n",
        "  print('\\nShape of Input Batch to LSTM (X_train.shape):', X_train.shape)\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "7SUk_KYXZkOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps_in = 4\n",
        "n_features = 10\n",
        "#n_timesteps_out = 2\n",
        "\n",
        "X, y = get_reversed_pairs(n_timesteps_in, n_features, verbose=True)\n",
        "train_size = 100\n",
        "test_size = 20\n",
        "\n",
        "X_train, y_train, X_test, y_test = create_dataset(train_size, test_size, n_timesteps_in, n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-iA7uLjnPkj",
        "outputId": "4517a134-2b08-4205-8b39-911361297046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sequences as follows\n",
            "\n",
            "One Sample Input Sequence in raw format:\n",
            "X[0]=[4, 2, 7, 5]\n",
            "\n",
            "In one_hot_encoded format:\n",
            "X[0]=[[0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]]\n",
            "\n",
            "Shape of an input to LSTm (X[0].shape): (1, 4, 10)\n",
            "\n",
            "Shape of Input Batch to LSTM (X_train.shape): (100, 4, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfLSTMunits = 16\n",
        "\n",
        "input = Input(shape=(n_timesteps_in, n_features))\n",
        "state_h = LSTM(numberOfLSTMunits) (input)\n",
        "model1 = Model(inputs= input, outputs=state_h)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVwfhrxFsuG7",
        "outputId": "5c71fcde-69a3-4129-a220-cf49936147e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4, 10)]           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16)                1728      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,728\n",
            "Trainable params: 1,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model1.predict(X_train)\n",
        "print('input shape', X_train.shape)\n",
        "print('state_h shape', result.shape)\n",
        "print('result for the first sample/input: \\n', result[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diYsFfaguNIz",
        "outputId": "2ee62d0a-5368-42ac-f76a-97454a6b477b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 7s 5ms/step\n",
            "input shape (100, 4, 10)\n",
            "state_h shape (100, 16)\n",
            "result for the first sample/input: \n",
            " [-0.09239276 -0.09985759 -0.15129723 -0.04877616 -0.01588167 -0.05418357\n",
            " -0.08187836 -0.00935194  0.04639095  0.07869623 -0.10670013  0.02275475\n",
            " -0.04578882 -0.00931439  0.03336338 -0.03551181]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfLSTMunits = 16\n",
        "\n",
        "input = Input(shape=(n_timesteps_in, n_features))\n",
        "all_state_h = LSTM(numberOfLSTMunits, return_sequences=True)(input)\n",
        "model1 = Model(inputs= input, outputs = all_state_h)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGRduQaUvC_Z",
        "outputId": "873ad458-8745-40e3-b355-558d30a793cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 4, 10)]           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 16)             1728      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,728\n",
            "Trainable params: 1,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model1.predict(X_train)\n",
        "\n",
        "print('input shape:', X_train.shape)\n",
        "print('all_state_h shape', result.shape)\n",
        "print('\\nhidden states for the first sample:\\n', result[0])\n",
        "print('\\nhidden states for the first sample at the second time step: \\n', result[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVl5mqx4v3S3",
        "outputId": "9c4d0ae1-7783-4c74-8865-0f95511e319a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 7ms/step\n",
            "input shape: (100, 4, 10)\n",
            "all_state_h shape (100, 4, 16)\n",
            "\n",
            "hidden states for the first sample:\n",
            " [[-0.02262436 -0.04754497  0.05966783  0.05943919  0.05058412 -0.05572051\n",
            "  -0.05256375 -0.05043213 -0.05960981  0.00568357  0.06567019 -0.01498767\n",
            "   0.01152137  0.0574741  -0.00426618  0.01170248]\n",
            " [-0.0950058  -0.10511314 -0.00615508  0.0963183  -0.04407406 -0.06496571\n",
            "  -0.09908493 -0.06814776 -0.08962796  0.03602935  0.11247353  0.00276205\n",
            "  -0.00132382 -0.01584579  0.05472199 -0.03059291]\n",
            " [-0.15198945 -0.14708824 -0.05052714  0.13142194 -0.12282782 -0.05671879\n",
            "  -0.12443785 -0.07534549 -0.11393125  0.06936996  0.1175988   0.01739546\n",
            "  -0.00655721 -0.0759122   0.1069563  -0.05251282]\n",
            " [-0.15954188 -0.09931306 -0.07926431  0.14535303 -0.11735033 -0.06293015\n",
            "  -0.01628185  0.00899775 -0.01372408  0.00669521  0.06697696  0.058496\n",
            "  -0.05457247 -0.04768565  0.04309651  0.0382362 ]]\n",
            "\n",
            "hidden states for the first sample at the second time step: \n",
            " [-0.0950058  -0.10511314 -0.00615508  0.0963183  -0.04407406 -0.06496571\n",
            " -0.09908493 -0.06814776 -0.08962796  0.03602935  0.11247353  0.00276205\n",
            " -0.00132382 -0.01584579  0.05472199 -0.03059291]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfLSTMunits = 16\n",
        "\n",
        "input = Input(shape=(n_timesteps_in, n_features))\n",
        "LSTM_output, state_h, state_c = LSTM(numberOfLSTMunits, return_state=True)(input)\n",
        "model1 = Model(inputs=input, outputs=[LSTM_output, state_h, state_c])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aDAnqmWDiSk",
        "outputId": "f63a25e4-efca-4efe-e03b-14aa9e47dbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 4, 10)]           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, 16),              1728      \n",
            "                              (None, 16),                        \n",
            "                              (None, 16)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,728\n",
            "Trainable params: 1,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input layer output shape:', model1.get_layer(index=0).output_shape)\n",
        "print('LSTM layer output shape:', model1.get_layer(index=1).output_shape)\n",
        "results = model1.predict(X_train)\n",
        "results = array(results)\n",
        "\n",
        "print('\\nWith batch of data:')\n",
        "print('input shape:', X_train.shape)\n",
        "print('result is 3 2D-array:', results.shape)\n",
        "print('\\nLSTM_output is in the first array:', results[0].shape)\n",
        "print('\\nstate_h which is exactly the same with LSTM_output is in the seconde array:', results[1].shape)\n",
        "print('\\nIs the content of LSTM_output and state_c exactly the same?\\n', results[0]==results[2])\n",
        "print('\\nstate_c is in the third array:', results[2].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9JdTXFGEgO5",
        "outputId": "b7381acf-15dd-4cd0-a5ee-65dc3c23b0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input layer output shape: [(None, 4, 10)]\n",
            "LSTM layer output shape: [(None, 16), (None, 16), (None, 16)]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "\n",
            "With batch of data:\n",
            "input shape: (100, 4, 10)\n",
            "result is 3 2D-array: (3, 100, 16)\n",
            "\n",
            "LSTM_output is in the first array: (100, 16)\n",
            "\n",
            "state_h which is exactly the same with LSTM_output is in the seconde array: (100, 16)\n",
            "\n",
            "Is the content of LSTM_output and state_c exactly the same?\n",
            " [[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n",
            "\n",
            "state_c is in the third array: (100, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfLSTMunits = 16\n",
        "\n",
        "input = Input (shape=(n_timesteps_in, n_features))\n",
        "all_state_h, state_h, state_c = LSTM(numberOfLSTMunits, return_sequences=True, return_state=True)(input)\n",
        "model1 = Model(inputs=input, outputs=[all_state_h, state_h, state_c])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1sL_uo7mw4R",
        "outputId": "bc3cf8c7-d422-4315-9ab8-6937a6649746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 4, 10)]           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               [(None, 4, 16),           1728      \n",
            "                              (None, 16),                        \n",
            "                              (None, 16)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,728\n",
            "Trainable params: 1,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model1.predict(X_train)\n",
        "print('\\nWith batch of data:')\n",
        "print('input shape:', X_train.shape)\n",
        "print('result is 3 2D-array len(results):',len(results))\n",
        "print('\\nall_state_h is in the first array:', results[0].shape)\n",
        "print('\\nstate_h is in the second array:', results[1].shape)\n",
        "print('\\nstate_c is in the third array:', results[2].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07WKMndbqGdh",
        "outputId": "474cc47c-7c4c-40d2-e9d7-e061a4122011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n",
            "\n",
            "With batch of data:\n",
            "input shape: (100, 4, 10)\n",
            "result is 3 2D-array len(results): 3\n",
            "\n",
            "all_state_h is in the first array: (100, 4, 16)\n",
            "\n",
            "state_h is in the second array: (100, 16)\n",
            "\n",
            "state_c is in the third array: (100, 16)\n"
          ]
        }
      ]
    }
  ]
}